<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.89.1" /><meta name="theme-color" content="#fff" />
    <meta name="color-scheme" content="light dark">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>TensorRT咨询Chatgpt | 不那么乐的世界</title>

    <link rel="stylesheet" href="../../css/meme.min.a51d2e78c88c28c2d1494764d47b2a2a6cd0677a3c5b1e9d1535668b0d0e2bb7.css"/>

    
    
        <script src="../../js/meme.min.9da7ceebb526f70d67ed0f4fe668252d38b01dc89412c8a51d63ff66ecde38d6.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" /></noscript>

    <meta name="author" content="chenbokai" /><meta name="description" content="TensorRT全栈开发的步骤与接口 1. 介绍一个tensorrt全栈的开发及步骤 Ten……" />

    <link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="../../icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="../../icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="不那么乐的世界" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="不那么乐的世界" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="../../manifest.json" />

    
    

    
    <link rel="canonical" href="https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2023-03-12T00:53:50+08:00",
        "dateModified": "2023-03-12T01:16:36+08:00",
        "url": "https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/",
        "headline": "TensorRT咨询Chatgpt",
        "description": "TensorRT全栈开发的步骤与接口 1. 介绍一个tensorrt全栈的开发及步骤 Ten……",
        "inLanguage" : "zh-CN",
        "articleSection": "tech",
        "wordCount":  4082 ,
        "image": "https://chenbokaix250.github.io/icons/apple-touch-icon.png",
        "author": {
            "@type": "Person",
            "description": "Viva La Vida",
            "email": "chenbokais3@gmail.com",
            "image": "https://chenbokaix250.github.io/icons/google.png",
            "url": "https://chenbokai.asia",
            "name": "chenbokai"
        },
        "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)",
        "publisher": {
            "@type": "Organization",
            "name": "不那么乐的世界",
            "logo": {
                "@type": "ImageObject",
                "url": "https://chenbokaix250.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://chenbokaix250.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://chenbokaix250.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@chenbokaiy450" />
<meta name="twitter:creator" content="@chenbokaiy450" />

    



<meta property="og:title" content="TensorRT咨询Chatgpt" />
<meta property="og:description" content="TensorRT全栈开发的步骤与接口 1. 介绍一个tensorrt全栈的开发及步骤 Ten……" />
<meta property="og:url" content="https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/" />
<meta property="og:site_name" content="不那么乐的世界" />
<meta property="og:locale" content="zh" /><meta property="og:image" content="https://chenbokaix250.github.io/icons/apple-touch-icon.png" />
    <meta property="og:type" content="article" />
    <meta property="article:published_time" content="2023-03-12T00:53:50&#43;08:00" />
    <meta property="article:modified_time" content="2023-03-12T01:16:36&#43;08:00" />
    
    <meta property="article:section" content="tech" />



    
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="../../" class="brand">不那么乐的世界</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="../../life/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon life"><path d="M301.1 212c4.4 4.4 4.4 11.9 0 16.3l-9.7 9.7c-4.4 4.7-11.9 4.7-16.6 0l-10.5-10.5c-4.4-4.7-4.4-11.9 0-16.6l9.7-9.7c4.4-4.4 11.9-4.4 16.6 0l10.5 10.8zm-30.2-19.7c3-3 3-7.8 0-10.5-2.8-3-7.5-3-10.5 0-2.8 2.8-2.8 7.5 0 10.5 3.1 2.8 7.8 2.8 10.5 0zm-26 5.3c-3 2.8-3 7.5 0 10.2 2.8 3 7.5 3 10.5 0 2.8-2.8 2.8-7.5 0-10.2-3-3-7.7-3-10.5 0zm72.5-13.3c-19.9-14.4-33.8-43.2-11.9-68.1 21.6-24.9 40.7-17.2 59.8.8 11.9 11.3 29.3 24.9 17.2 48.2-12.5 23.5-45.1 33.2-65.1 19.1zm47.7-44.5c-8.9-10-23.3 6.9-15.5 16.1 7.4 9 32.1 2.4 15.5-16.1zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-66.2 42.6c2.5-16.1-20.2-16.6-25.2-25.7-13.6-24.1-27.7-36.8-54.5-30.4 11.6-8 23.5-6.1 23.5-6.1.3-6.4 0-13-9.4-24.9 3.9-12.5.3-22.4.3-22.4 15.5-8.6 26.8-24.4 29.1-43.2 3.6-31-18.8-59.2-49.8-62.8-22.1-2.5-43.7 7.7-54.3 25.7-23.2 40.1 1.4 70.9 22.4 81.4-14.4-1.4-34.3-11.9-40.1-34.3-6.6-25.7 2.8-49.8 8.9-61.4 0 0-4.4-5.8-8-8.9 0 0-13.8 0-24.6 5.3 11.9-15.2 25.2-14.4 25.2-14.4 0-6.4-.6-14.9-3.6-21.6-5.4-11-23.8-12.9-31.7 2.8.1-.2.3-.4.4-.5-5 11.9-1.1 55.9 16.9 87.2-2.5 1.4-9.1 6.1-13 10-21.6 9.7-56.2 60.3-56.2 60.3-28.2 10.8-77.2 50.9-70.6 79.7.3 3 1.4 5.5 3 7.5-2.8 2.2-5.5 5-8.3 8.3-11.9 13.8-5.3 35.2 17.7 24.4 15.8-7.2 29.6-20.2 36.3-30.4 0 0-5.5-5-16.3-4.4 27.7-6.6 34.3-9.4 46.2-9.1 8 3.9 8-34.3 8-34.3 0-14.7-2.2-31-11.1-41.5 12.5 12.2 29.1 32.7 28 60.6-.8 18.3-15.2 23-15.2 23-9.1 16.6-43.2 65.9-30.4 106 0 0-9.7-14.9-10.2-22.1-17.4 19.4-46.5 52.3-24.6 64.5 26.6 14.7 108.8-88.6 126.2-142.3 34.6-20.8 55.4-47.3 63.9-65 22 43.5 95.3 94.5 101.1 59z"/></svg><span class="menu-item-name">生活</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="../../tech/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tech"><path d="M512 256c0 141.2-114.7 256-256 256C114.8 512 0 397.3 0 256S114.7 0 256 0s256 114.7 256 256zm-32 0c0-123.2-100.3-224-224-224C132.5 32 32 132.5 32 256s100.5 224 224 224 224-100.5 224-224zM160.9 124.6l86.9 37.1-37.1 86.9-86.9-37.1 37.1-86.9zm110 169.1l46.6 94h-14.6l-50-100-48.9 100h-14l51.1-106.9-22.3-9.4 6-14 68.6 29.1-6 14.3-16.5-7.1zm-11.8-116.3l68.6 29.4-29.4 68.3L230 246l29.1-68.6zm80.3 42.9l54.6 23.1-23.4 54.3-54.3-23.1 23.1-54.3z"/></svg><span class="menu-item-name">技术</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="../../about/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon about"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">关于</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="../../tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">标签</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
                    
                        
                        
                    
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="tech" data-toc-num="true">

            <h1 class="post-title p-name">TensorRT咨询Chatgpt</h1>

            

            
                
            

            
                

<div class="post-meta">
    
        
        <time datetime="2023-03-12T00:53:50&#43;08:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;2023.3.12</time>
    
    
        
        <time datetime="2023-03-12T01:16:36&#43;08:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2023.3.12</time>
    
    
    
        
        
            
            
                
                
                
                
                    
                    
                    
                        
                            
                            
                        
                    
                
            
            
            
                <span class="post-meta-item category"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>&nbsp;<a href="../../tech/" class="category-link p-category">Tech</a></span>
            
        
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;4082</span>
    
    
        
        <span class="post-meta-item reading-time"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;9&nbsp;分钟</span>
    
    
    
</div>

            

            <nav class="contents">
  <h2 id="contents" class="contents-title">目录</h2><ol class="toc">
    <li><a id="contents:1-介绍一个tensorrt全栈的开发及步骤" href="#1-介绍一个tensorrt全栈的开发及步骤">1. 介绍一个tensorrt全栈的开发及步骤</a></li>
    <li><a id="contents:2-用caffe-tensorflow-pytorch训练的模型-在转换后-部署是没有差异的么" href="#2-用caffe-tensorflow-pytorch训练的模型-在转换后-部署是没有差异的么">2. 用caffe tensorflow pytorch训练的模型 在转换后 部署是没有差异的么</a></li>
    <li><a id="contents:3-以minist为例子-介绍pytorch开发模型后-在orin平台部署的步骤" href="#3-以minist为例子-介绍pytorch开发模型后-在orin平台部署的步骤">3. 以minist为例子 介绍pytorch开发模型后 在orin平台部署的步骤</a></li>
    <li><a id="contents:4-使用c实现pytorch在平台上部署mnist" href="#4-使用c实现pytorch在平台上部署mnist">4. 使用c++实现pytorch在平台上部署mnist</a></li>
    <li><a id="contents:34-步骤的代码" href="#34-步骤的代码">3/4 步骤的代码</a></li>
  </ol>
</nav><div class="post-body e-content">
                <h1 id="tensorrt全栈开发的步骤与接口"><a href="#tensorrt全栈开发的步骤与接口" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:tensorrt全栈开发的步骤与接口" class="headings">TensorRT全栈开发的步骤与接口</a></h1>
<h2 id="1-介绍一个tensorrt全栈的开发及步骤"><a href="#1-介绍一个tensorrt全栈的开发及步骤" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:1-介绍一个tensorrt全栈的开发及步骤" class="headings">1. 介绍一个tensorrt全栈的开发及步骤</a></h2>
<p>TensorRT是英伟达推出的用于高性能深度学习推理的优化器和推理引擎。它可以将深度学习模型转换为高效的计算图，从而提高模型的推理性能。TensorRT的全栈开发主要包括以下步骤：</p>
<ol>
<li>
<p>准备模型：选择需要部署的深度学习模型，并将其转换为可用于TensorRT的格式，如Caffe、ONNX、TensorFlow等。可以使用TensorRT提供的工具，如TensorRT Parser API和ONNX-TensorRT等，来将模型转换为TensorRT可用的格式。</p>
</li>
<li>
<p>优化模型：使用TensorRT的优化器来优化模型，以提高推理性能。TensorRT的优化器会自动将计算图转换为高效的计算图，同时还可以进行层融合、减少精度等操作，以进一步提高性能。TensorRT还支持自定义插件，可以使用插件来实现一些特定的操作，如卷积等。</p>
</li>
<li>
<p>部署模型：将优化后的模型部署到目标平台上，可以使用TensorRT的C++ API或Python API进行部署。在部署过程中，需要设置输入和输出张量的维度，以及设置推理的batch size等参数。可以使用TensorRT提供的Profiler API来对推理过程进行性能分析。</p>
</li>
<li>
<p>集成模型：将部署好的模型集成到应用程序中。可以使用TensorRT提供的TensorRT Inference Server来构建和管理深度学习推理服务，或使用TensorRT的插件来将模型集成到现有的推理框架中，如TensorFlow Serving、PyTorch Serving等。</p>
</li>
</ol>
<p>需要注意的是，TensorRT全栈开发需要对深度学习模型、计算图优化、推理引擎等方面都有一定的了解和经验。同时，也需要熟悉C++或Python等编程语言。</p>
<h2 id="2-用caffe-tensorflow-pytorch训练的模型-在转换后-部署是没有差异的么"><a href="#2-用caffe-tensorflow-pytorch训练的模型-在转换后-部署是没有差异的么" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:2-用caffe-tensorflow-pytorch训练的模型-在转换后-部署是没有差异的么" class="headings">2. 用caffe tensorflow pytorch训练的模型 在转换后 部署是没有差异的么</a></h2>
<p>在使用TensorRT进行深度学习模型的优化和部署时，不同的深度学习框架的模型转换和部署步骤略有不同，但总体上可以使用TensorRT Parser API和ONNX-TensorRT等工具将各种深度学习框架训练出的模型转换为TensorRT可用的格式，然后使用TensorRT的C++ API或Python API进行部署。因此，在使用TensorRT进行深度学习模型的优化和部署时，各种深度学习框架的模型在转换后，基本上是没有差异的。</p>
<p>需要注意的是，不同深度学习框架的模型在转换为TensorRT可用的格式时，可能需要进行一些框架特定的操作，如caffe模型需要进行caffe模型文件(.prototxt)和caffe模型权重文件(.caffemodel)的转换，而TensorFlow模型需要进行Frozen Graph的转换等。另外，由于TensorRT在计算图优化和推理引擎方面的优化策略和实现细节有所不同，因此不同框架训练的模型在经过TensorRT优化后，可能会存在一定的性能差异。</p>
<h2 id="3-以minist为例子-介绍pytorch开发模型后-在orin平台部署的步骤"><a href="#3-以minist为例子-介绍pytorch开发模型后-在orin平台部署的步骤" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:3-以minist为例子-介绍pytorch开发模型后-在orin平台部署的步骤" class="headings">3. 以minist为例子 介绍pytorch开发模型后 在orin平台部署的步骤</a></h2>
<p>MINIST是一个手写数字识别数据集，可以用来训练图像分类模型。在PyTorch中，我们可以使用torchvision库来加载MINIST数据集并构建模型。在训练完模型后，我们需要将其部署到某个平台上，以便可以在生产环境中使用。在这里，我将介绍将PyTorch模型部署到ONNX Runtime（Orin）平台的步骤。</p>
<p>步骤一：训练模型</p>
<p>首先，我们需要在PyTorch中训练一个MINIST分类模型。这可以通过以下步骤完成：</p>
<ol>
<li>加载MINIST数据集</li>
<li>定义模型架构</li>
<li>定义损失函数和优化器</li>
<li>训练模型</li>
<li>保存训练好的模型</li>
</ol>
<p>一个简单的示例代码如下：</p>
<pre tabindex="0"><code>import torch
import torchvision
import torchvision.transforms as transforms

# 加载MINIST数据集
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.1307,), (0.3081,))])

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64,
                                         shuffle=False, num_workers=2)

# 定义模型架构
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = torch.nn.Conv2d(1, 6, 5)
        self.pool = torch.nn.MaxPool2d(2, 2)
        self.conv2 = torch.nn.Conv2d(6, 16, 5)
        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)
        self.fc2 = torch.nn.Linear(120, 84)
        self.fc3 = torch.nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(torch.nn.functional.relu(self.conv1(x)))
        x = self.pool(torch.nn.functional.relu(self.conv2(x)))
        x = x.view(-1, 16 * 4 * 4)
        x = torch.nn.functional.relu(self.fc1(x))
        x = torch.nn.functional.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# 定义损失函数和优化器
net = Net()
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

# 训练模型
for epoch in range(10):  # 迭代10次
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 99:  # 每100个batch输出一次loss
            print('[%d, %5d] loss
</code></pre><p>步骤二：将PyTorch模型转换为ONNX格式</p>
<p>一旦我们在PyTorch中训练好了模型，我们需要将它转换为ONNX格式，以便在ONNX Runtime（Orin）平台上运行。ONNX是一种跨平台、开放标准的神经网络框架，可以在多个框架之间转换模型，例如TensorFlow、Caffe和PyTorch等。</p>
<p>我们可以使用torch.onnx.export函数将PyTorch模型转换为ONNX格式。该函数需要指定输入张量的形状、模型的输出张量名称以及要保存的文件名。</p>
<p>以下是将MINIST分类模型转换为ONNX格式的示例代码：</p>
<pre tabindex="0"><code># 将PyTorch模型转换为ONNX格式
dummy_input = torch.randn(1, 1, 28, 28)
input_names = ['input']
output_names = ['output']
torch.onnx.export(net, dummy_input, 'minist.onnx', verbose=True, input_names=input_names, output_names=output_names)
</code></pre><p>步骤三：在ONNX Runtime（Orin）平台上部署模型</p>
<p>一旦我们已经将PyTorch模型转换为ONNX格式，我们可以在ONNX Runtime（Orin）平台上部署它。在此之前，我们需要安装ONNX Runtime（Orin）库并将ONNX模型加载到运行时中。</p>
<p>以下是将MINIST分类模型部署到ONNX Runtime（Orin）平台的示例代码：</p>
<pre tabindex="0"><code>import onnxruntime as ort

# 加载ONNX模型
ort_session = ort.InferenceSession('minist.onnx')

# 测试模型
inputs = {ort_session.get_inputs()[0].name: testset[0][0].numpy()}
outputs = ort_session.run(None, inputs)
predicted = np.argmax(outputs)
print('Prediction:', predicted)
</code></pre><p>在此示例中，我们首先使用onnxruntime.InferenceSession函数加载ONNX模型，然后使用get_inputs函数获取模型的输入张量，用numpy数组作为输入，然后使用run函数在模型上运行推理并获取输出结果。最后，我们使用numpy.argmax函数获取预测结果并将其打印出来。</p>
<p>这就是将PyTorch模型部署到ONNX Runtime（Orin）平台的步骤。在实际应用中，我们可能需要对部署过程进行更多的调试和优化，以确保模型在生产环境中能够正常工作。</p>
<h2 id="4-使用c实现pytorch在平台上部署mnist"><a href="#4-使用c实现pytorch在平台上部署mnist" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:4-使用c实现pytorch在平台上部署mnist" class="headings">4. 使用c++实现pytorch在平台上部署mnist</a></h2>
<p>要在 C++ 中使用 ONNX Runtime（Orin）运行转换后的 PyTorch 模型，需要按照以下步骤进行操作：</p>
<ol>
<li>
<p>安装 ONNX Runtime（Orin）库
可以通过官方网站下载并安装适用于您的操作系统和硬件的 ONNX Runtime（Orin）库。或者，您可以使用适用于 C++ 的预编译库或源代码来构建和安装 ONNX Runtime（Orin）库。</p>
</li>
<li>
<p>加载 ONNX 模型
ONNX Runtime（Orin）支持在 C++ 中加载和运行 ONNX 格式的模型。可以使用 Ort::Env 和 Ort::Session 类来加载和运行模型。</p>
</li>
</ol>
<p>下面是加载 MINIST 分类模型的示例代码：</p>
<pre tabindex="0"><code>#include &lt;onnxruntime_cxx_api.h&gt;
#include &lt;iostream&gt;

int main() {
    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, &quot;test&quot;);
    Ort::Session session(env, &quot;minist.onnx&quot;, Ort::SessionOptions{nullptr});

    Ort::AllocatorWithDefaultOptions allocator;

    // 获取输入张量
    const char* inputName = session.GetInputName(0, allocator);
    Ort::TypeInfo inputTypeInfo = session.GetInputTypeInfo(0);
    auto inputTensorInfo = inputTypeInfo.GetTensorTypeAndShapeInfo();

    // 创建输入张量
    std::vector&lt;int64_t&gt; inputDims = {1, 1, 28, 28};
    std::vector&lt;float&gt; inputValues(1 * 1 * 28 * 28);
    auto memoryInfo = Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeDefault);
    auto inputTensor = Ort::Value::CreateTensor&lt;float&gt;(memoryInfo, inputValues.data(), inputValues.size(), inputDims.data(), inputDims.size());

    // 获取输出张量
    const char* outputName = session.GetOutputName(0, allocator);
    Ort::TypeInfo outputTypeInfo = session.GetOutputTypeInfo(0);
    auto outputTensorInfo = outputTypeInfo.GetTensorTypeAndShapeInfo();

    // 运行模型
    Ort::RunOptions runOptions;
    auto outputValues = session.Run(runOptions, &amp;inputName, &amp;inputTensor, 1, &amp;outputName, 1);
    auto outputTensor = outputValues.front().Get&lt;Tensor&gt;();

    // 获取预测结果
    std::vector&lt;float&gt; outputData(outputTensorInfo.GetElementCount());
    outputTensor.CopyTo(outputData.data(), outputData.size() * sizeof(float));
    int prediction = std::distance(outputData.begin(), std::max_element(outputData.begin(), outputData.end()));
    std::cout &lt;&lt; &quot;Prediction: &quot; &lt;&lt; prediction &lt;&lt; std::endl;
    
    return 0;
}

</code></pre><ol start="3">
<li>运行模型并获取预测结果
在 C++ 中运行模型的过程与在 Python 中运行模型类似，需要将输入张量传递给模型，然后获取模型的输出张量并将其转换为适当的格式。</li>
</ol>
<p>在上面的示例代码中，我们首先获取输入张量的名称和类型信息，然后创建一个新的输入张量，设置其形状和数据，并将其传递给模型。接下来，我们获取输出张量的名称和类型信息，运行模型并获取输出张量的值。最后，我们使用 std::max_element 函数查找输出张量中最大值所在的索引，并将其作为预测结果返回。</p>
<p>请注意，上面的示例代码仅适用于输入为大小为 28x28 的灰度图像，并且假定输入和输出张量均为浮点型。如果您的模型具有不同的输入或输出形状或数据类型，请相应地更改示例代码。</p>
<p>编译并运行 C++ 代码
在将 C++ 代码与 ONNX Runtime（Orin）库链接之前，需要将 ONNX Runtime（Orin）头文件和库添加到编译器的搜索路径中。使用适当的编译器选项将 C++ 代码与 ONNX Runtime（Orin）库链接，并生成可执行文件。</p>
<p>在 Linux 系统上，可以使用以下命令编译 C++ 代码：</p>
<p><code>g++ -std=c++11 -I /path/to/onnxruntime/include -L /path/to/onnxruntimelib -l onnxruntime_cxx -l onnxruntime_framework mnist.cpp -o mnist</code></p>
<p>在 Windows 系统上，可以使用以下命令编译 C++ 代码：</p>
<p><code>cl.exe /EHsc /I C:\path\to\onnxruntime\include /link /LIBPATH:C:\path\to\onnxruntime\lib onnxruntime.lib onnxruntime_framework.lib mnist.cpp /out:mnist.exe</code></p>
<p>完成编译后，运行生成的可执行文件即可使用训练好的模型进行分类预测。</p>
<p>总之，在使用 PyTorch 训练模型并将其导出为 ONNX 格式后，可以使用 ONNX Runtime（Orin）库在 C++ 中加载和运行模型。为了实现此目标，您需要下载并安装适用于您的操作系统和硬件的 ONNX Runtime（Orin）库，并使用 Ort::Env 和 Ort::Session 类加载和运行模型。然后，您可以将 C++ 代码与 ONNX Runtime（Orin）库链接，并生成可执行文件。</p>
<h2 id="34-步骤的代码"><a href="#34-步骤的代码" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:34-步骤的代码" class="headings">3/4 步骤的代码</a></h2>
<ol start="3">
<li>加载并运行模型
在 C++ 代码中加载和运行模型的示例代码如下：</li>
</ol>
<pre tabindex="0"><code>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;onnxruntime_cxx_api.h&gt;

int main() {
    // 创建 Ort::Env 对象
    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, &quot;mnist&quot;);

    // 创建 Ort::SessionOptions 对象
    Ort::SessionOptions session_options;
    session_options.SetIntraOpNumThreads(1);

    // 加载模型
    const char* model_path = &quot;mnist.onnx&quot;;
    Ort::Session session(env, model_path, session_options);

    // 获取模型的输入和输出名称、形状和数据类型
    std::vector&lt;const char*&gt; input_names = session.GetInputNames();
    std::vector&lt;const char*&gt; output_names = session.GetOutputNames();
    Ort::TypeInfo input_type_info = session.GetInputTypeInfo(0);
    Ort::TypeInfo output_type_info = session.GetOutputTypeInfo(0);
    auto input_tensor_info = input_type_info.GetTensorTypeAndShapeInfo();
    auto output_tensor_info = output_type_info.GetTensorTypeAndShapeInfo();
    std::vector&lt;int64_t&gt; input_shape = input_tensor_info.GetShape();
    std::vector&lt;int64_t&gt; output_shape = output_tensor_info.GetShape();
    ONNXTensorElementDataType input_type = input_tensor_info.GetElementType();
    ONNXTensorElementDataType output_type = output_tensor_info.GetElementType();

    // 分配输入和输出张量的内存
    size_t input_tensor_size = 1;
    size_t output_tensor_size = 1;
    for (const auto&amp; dim : input_shape) {
        input_tensor_size *= dim;
    }
    for (const auto&amp; dim : output_shape) {
        output_tensor_size *= dim;
    }
    std::vector&lt;float&gt; input_data(input_tensor_size);
    std::vector&lt;float&gt; output_data(output_tensor_size);

    // 初始化输入张量
    // 假设输入张量为大小为 28x28 的灰度图像，其中每个像素的值在 [0, 1] 之间
    // input_data 为大小为 784 的一维数组，其中每个元素的值在 [0, 1] 之间
    // 如果输入张量有不同的形状或数据类型，请相应地更改此代码
    // 如果输入数据不在 [0, 1] 范围内，需要进行归一化或缩放处理
    for (size_t i = 0; i &lt; input_tensor_size; ++i) {
        input_data[i] = i / static_cast&lt;float&gt;(input_tensor_size);
    }

    // 创建 Ort::Value 对象以表示输入和输出张量
    Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeDefault);
    Ort::Value input_tensor = Ort::Value::CreateTensor&lt;float&gt;(memory_info, input_data.data(), input_tensor_size, input_shape.data(), input_shape.size());
    Ort::Value output_tensor = Ort::Value::CreateTensor&lt;float&gt;(memory_info, output_data.data(), output_tensor_size, output_shape.data(), output_shape.size());

    // 运行模型
    std::vector&lt;Ort::Value&gt; input_tensors = {input_tensor};
    std::vector&lt;Ort::Value&gt; output_tensors = {output_tensor};
    session.Run(Ort::RunOptions{}, input_names.data(), input_tensors.data(), input_names
</code></pre><ol start="4">
<li>解析模型输出
在 C++ 代码中解析模型输出的示例代码如下：</li>
</ol>
<pre tabindex="0"><code>    // 获取模型的输出
    float* output_data_ptr = output_tensor.GetTensorMutableData&lt;float&gt;();
    std::vector&lt;float&gt; output_data(output_data_ptr, output_data_ptr + output_tensor_size);

    // 输出模型的输出
    // 假设模型的输出是 10 个类别的概率值
    // 需要将输出概率值最大的类别作为预测结果
    // 如果输出数据不是一维数组或不是浮点数，请相应地更改此代码
    int predicted_class = -1;
    float max_probability = -1.0f;
    for (int i = 0; i &lt; output_tensor_size; ++i) {
        if (output_data[i] &gt; max_probability) {
            predicted_class = i;
            max_probability = output_data[i];
        }
    }
    std::cout &lt;&lt; &quot;Predicted class: &quot; &lt;&lt; predicted_class &lt;&lt; std::endl;

    return 0;
}

</code></pre><p>该代码从输出张量中获取浮点数数组，并找到最大值所在的索引作为预测结果。如果输出数据不是一维数组或不是浮点数，则需要相应地更改该代码。</p>
<hr>
<p>cahtgpt查找和记录</p>

            </div>

            
    
    
        <ul class="post-copyright">
            <li class="copyright-item author"><span class="copyright-item-text">作者</span>：<a href="https://chenbokai.asia" class="p-author h-card" target="_blank" rel="noopener">chenbokai</a></li>
            
                
                
                
                
                <li class="copyright-item link"><span class="copyright-item-text">链接</span>：<a href="../../tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/" target="_blank" rel="noopener">https://chenbokaix250.github.io/tech/tensorrt咨询chatgpt/</a></li>
            
            <li class="copyright-item license"><span class="copyright-item-text">许可</span>：<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></li>
            
        </ul>
    



        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2023-03-12 01:16:36 CST" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2023-03-12</text><text x="915" y="140" textLength="650" transform="scale(.1)">2023-03-12</text></g></svg>
        </span></div>



        


        <div class="post-share">

        

        <div class="share-items">

            
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;text=TensorRT%e5%92%a8%e8%af%a2Chatgpt&amp;hashtags=&amp;via=chenbokaiy450" title="分享到「Twitter」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            
                <div class="share-item facebook">
                    
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;hashtag=%23" title="分享到「Facebook」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a>
                </div>
            

            
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;title=TensorRT%e5%92%a8%e8%af%a2Chatgpt&amp;summary=TensorRT%e5%85%a8%e6%a0%88%e5%bc%80%e5%8f%91%e7%9a%84%e6%ad%a5%e9%aa%a4%e4%b8%8e%e6%8e%a5%e5%8f%a3%201.%20%e4%bb%8b%e7%bb%8d%e4%b8%80%e4%b8%aatensorrt%e5%85%a8%e6%a0%88%e7%9a%84%e5%bc%80%e5%8f%91%e5%8f%8a%e6%ad%a5%e9%aa%a4%20Ten%e2%80%a6%e2%80%a6&amp;source=%e4%b8%8d%e9%82%a3%e4%b9%88%e4%b9%90%e7%9a%84%e4%b8%96%e7%95%8c" title="分享到「LinkedIn」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;text=TensorRT%e5%92%a8%e8%af%a2Chatgpt" title="分享到「Telegram」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            
                <div class="share-item weibo">
                    
                    <a href="https://service.weibo.com/share/share.php?&amp;url=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;title=TensorRT%e5%92%a8%e8%af%a2Chatgpt&amp;pic=https://chenbokaix250.github.io/icons/apple-touch-icon.png&amp;searchPic=false" title="分享到「新浪微博」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon weibo-icon"><path d="M407 177.6c7.6-24-13.4-46.8-37.4-41.7-22 4.8-28.8-28.1-7.1-32.8 50.1-10.9 92.3 37.1 76.5 84.8-6.8 21.2-38.8 10.8-32-10.3zM214.8 446.7C108.5 446.7 0 395.3 0 310.4c0-44.3 28-95.4 76.3-143.7C176 67 279.5 65.8 249.9 161c-4 13.1 12.3 5.7 12.3 6 79.5-33.6 140.5-16.8 114 51.4-3.7 9.4 1.1 10.9 8.3 13.1 135.7 42.3 34.8 215.2-169.7 215.2zm143.7-146.3c-5.4-55.7-78.5-94-163.4-85.7-84.8 8.6-148.8 60.3-143.4 116s78.5 94 163.4 85.7c84.8-8.6 148.8-60.3 143.4-116zM347.9 35.1c-25.9 5.6-16.8 43.7 8.3 38.3 72.3-15.2 134.8 52.8 111.7 124-7.4 24.2 29.1 37 37.4 12 31.9-99.8-55.1-195.9-157.4-174.3zm-78.5 311c-17.1 38.8-66.8 60-109.1 46.3-40.8-13.1-58-53.4-40.3-89.7 17.7-35.4 63.1-55.4 103.4-45.1 42 10.8 63.1 50.2 46 88.5zm-86.3-30c-12.9-5.4-30 .3-38 12.9-8.3 12.9-4.3 28 8.6 34 13.1 6 30.8.3 39.1-12.9 8-13.1 3.7-28.3-9.7-34zm32.6-13.4c-5.1-1.7-11.4.6-14.3 5.4-2.9 5.1-1.4 10.6 3.7 12.9 5.1 2 11.7-.3 14.6-5.4 2.8-5.2 1.1-10.9-4-12.9z"/></svg></a>
                </div>
            

            
                <div class="share-item douban">
                    
                    <a href="https://www.douban.com/share/service?href=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;name=TensorRT%e5%92%a8%e8%af%a2Chatgpt&amp;text=TensorRT%e5%85%a8%e6%a0%88%e5%bc%80%e5%8f%91%e7%9a%84%e6%ad%a5%e9%aa%a4%e4%b8%8e%e6%8e%a5%e5%8f%a3%201.%20%e4%bb%8b%e7%bb%8d%e4%b8%80%e4%b8%aatensorrt%e5%85%a8%e6%a0%88%e7%9a%84%e5%bc%80%e5%8f%91%e5%8f%8a%e6%ad%a5%e9%aa%a4%20Ten%e2%80%a6%e2%80%a6" title="分享到「豆瓣」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon douban-icon"><path d="M.643.92v2.412h22.714V.92H.643zm1.974 4.926v9.42h18.764v-9.42H2.617zm2.72 2.408H18.69v4.605H5.338V8.254zm1.657 7.412l-2.512.938c1.037 1.461 1.87 2.825 2.512 4.091H0v2.385h24v-2.385h-6.678c.818-1.176 1.589-2.543 2.303-4.091l-2.73-.938a29.952 29.952 0 01-2.479 5.03h-4.75c-.786-1.962-1.677-3.641-2.672-5.03Z"/></svg></a>
                </div>
            

            
                <div class="share-item qq">
                    
                    <a href="https://connect.qq.com/widget/shareqq/index.html?url=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;title=TensorRT%e5%92%a8%e8%af%a2Chatgpt&amp;summary=TensorRT%e5%85%a8%e6%a0%88%e5%bc%80%e5%8f%91%e7%9a%84%e6%ad%a5%e9%aa%a4%e4%b8%8e%e6%8e%a5%e5%8f%a3%201.%20%e4%bb%8b%e7%bb%8d%e4%b8%80%e4%b8%aatensorrt%e5%85%a8%e6%a0%88%e7%9a%84%e5%bc%80%e5%8f%91%e5%8f%8a%e6%ad%a5%e9%aa%a4%20Ten%e2%80%a6%e2%80%a6&amp;pics=https://chenbokaix250.github.io/icons/apple-touch-icon.png&amp;site=%e4%b8%8d%e9%82%a3%e4%b9%88%e4%b9%90%e7%9a%84%e4%b8%96%e7%95%8c" title="分享到「QQ」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qq-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                </div>
            

            
                <div class="share-item qzone">
                    
                    <a href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://chenbokaix250.github.io/tech/tensorrt%E5%92%A8%E8%AF%A2chatgpt/&amp;title=TensorRT%e5%92%a8%e8%af%a2Chatgpt&amp;summary=TensorRT%e5%85%a8%e6%a0%88%e5%bc%80%e5%8f%91%e7%9a%84%e6%ad%a5%e9%aa%a4%e4%b8%8e%e6%8e%a5%e5%8f%a3%201.%20%e4%bb%8b%e7%bb%8d%e4%b8%80%e4%b8%aatensorrt%e5%85%a8%e6%a0%88%e7%9a%84%e5%bc%80%e5%8f%91%e5%8f%8a%e6%ad%a5%e9%aa%a4%20Ten%e2%80%a6%e2%80%a6&amp;pics=https://chenbokaix250.github.io/icons/apple-touch-icon.png&amp;site=%e4%b8%8d%e9%82%a3%e4%b9%88%e4%b9%90%e7%9a%84%e4%b8%96%e7%95%8c" title="分享到「QQ 空间」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon qzone-icon"><path d="M23.985 9.202c-.032-.099-.127-.223-.334-.258-.207-.036-7.351-1.406-7.351-1.406s-.105-.022-.198-.07c-.092-.047-.127-.167-.127-.167S12.447.956 12.349.77C12.25.583 12.104.532 12 .532c-.104 0-.251.051-.349.238-.098.186-3.626 6.531-3.626 6.531s-.035.12-.128.167c-.092.047-.197.07-.197.07S.556 8.908.348 8.943c-.208.036-.302.16-.333.258a.477.477 0 0 0 .125.449l5.362 5.49s.072.08.119.172c.016.104.005.21.005.21s-1.189 7.242-1.22 7.45.075.369.159.43c.083.062.233.106.421.013.189-.093 6.812-3.261 6.812-3.261s.098-.044.201-.061c.103-.017.201.061.201.061s6.623 3.168 6.812 3.261c.188.094.338.049.421-.013a.463.463 0 0 0 .159-.43c-.021-.14-.93-5.677-.93-5.677.876-.54 1.425-1.039 1.849-1.747-2.594.969-6.006 1.717-9.415 1.866-.915.041-2.41.097-3.473-.015-.678-.071-1.17-.144-1.243-.438-.053-.215.054-.46.545-.831a2640.5 2640.5 0 0 1 2.861-2.155c1.285-.968 3.559-2.47 3.559-2.731 0-.285-2.144-.781-4.037-.781-1.945 0-2.275.132-2.811.168-.488.034-.769.005-.804-.138-.06-.248.183-.389.588-.568.709-.314 1.86-.594 1.984-.626.194-.052 3.082-.805 5.618-.535 1.318.14 3.244.668 3.244 1.276 0 .342-1.721 1.494-3.225 2.597-1.149.843-2.217 1.561-2.217 1.688 0 .342 3.533 1.241 6.689 1.01l.003-.022c.048-.092.119-.172.119-.172l5.362-5.49a.477.477 0 0 0 .127-.449z"/></svg></a>
                </div>
            

            
                <div class="share-item qrcode">
                    <div class="qrcode-container" title="通过「二维码」"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    var typeNumber = 0;
    var errorCorrectionLevel = 'L';
    var qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/chenbokaix250.github.io\/tech\/tensorrt%E5%92%A8%E8%AF%A2chatgpt\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                </div>
            

        </div>

    </div>




        
    
    



        
    



        


        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
                <li class="post-nav-prev">
                    <a href="../../tech/c&#43;&#43;acm%E6%A8%A1%E5%BC%8F%E6%94%BB%E7%95%A5/" rel="prev">&lt; C++ACM模式攻略</a>
                </li>
            
            
                <li class="post-nav-next">
                    <a href="../../tech/gdb%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/" rel="next">Gdb调试记录 &gt;</a>
                </li>
            
        </ul>
    



        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">©&nbsp;2020–2024&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;chenbokai</div><div class="powered-by">Powered by <a href="https://github.com/gohugoio/hugo" target="_blank" rel="noopener">Hugo</a> | Theme is <a href="https://github.com/reuixiy/hugo-theme-meme" target="_blank" rel="noopener">MemE</a></div><div class="site-copyright"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a></div>
                <div class="busuanzi-site-uv-and-pv">
                    <span id="busuanzi_container_site_uv">本站访客数&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon busuanzi-site-uv"><path d="M224 256c70.7 0 128-57.3 128-128S294.7 0 224 0 96 57.3 96 128s57.3 128 128 128zm89.6 32h-16.7c-22.2 10.2-46.9 16-72.9 16s-50.6-5.8-72.9-16h-16.7C60.2 288 0 348.2 0 422.4V464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48v-41.6c0-74.2-60.2-134.4-134.4-134.4z"/></svg>&nbsp;<span id="busuanzi_value_site_uv"></span></span>&nbsp;|&nbsp;<span id="busuanzi_container_site_pv">本站访问量&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon busuanzi-site-pv"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg>&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                </div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="../../rss.xml" target="_blank" rel="external noopener" title="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"/></svg></a>
                </li><li class="socials-item">
                    <a href="chenbokais3@gmail.com" target="_blank" rel="external noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/chenbokaix250" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://twitter.com/chenbokaiy450" target="_blank" rel="external noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://t.me/tellmewhy321" target="_blank" rel="external noopener" title="Telegram"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon social-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </li></ul>
    



            
        </div>
    </footer>


        </div>
        

        








    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    let imgNodes = document.querySelectorAll('div.post-body img');
    imgNodes = Array.from(imgNodes).filter(node => node.parentNode.tagName !== "A");

    mediumZoom(imgNodes, {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>




    
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    




    </body>
</html>
